{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于RAG技术的知识问答\n",
    "\n",
    "数据来源：arXiv\n",
    "\n",
    "任务：\n",
    "\n",
    "    1. 输入用户问题\n",
    "    2. 搜索向量存储库找出匹配的论文abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化\n",
    "\n",
    "1. llm:Qwen2.5-14B模型\n",
    "\n",
    "2. embedding\n",
    ">`sentence-transformers/all-MiniLM-L12-v2` 是 `sentence-transformers` 项目下的一个很受欢迎的预训练模型。它擅长将句子级别的文本转换为高质量的向量表示，能够很好地捕捉句子的语义信息，并且生成的向量维度相对合理（通常在计算和存储成本上有较好的平衡）。\n",
    ">\n",
    ">这个模型在诸多文本相似性任务中表现出色，例如在文本聚类、语义搜索、问答匹配等场景下，可以基于它生成的向量快速准确地找到语义相近的文本内容\n",
    "\n",
    "3. 数据arXiv下载（如果搞自己的本地离线向量数据库）\n",
    "\n",
    "3. 向量数据库Milvus\n",
    ">Milvus 是一款开源的、专门用于处理海量向量数据的数据库管理系统。它旨在高效地存储、索引以及快速检索高维向量数据，能够很好地支持各种基于向量相似度的应用，比如在自然语言处理领域的语义搜索、图像识别领域的图像特征匹配等场景中发挥重要作用。与传统的关系型数据库不同，它聚焦于向量这种数据形式，针对向量的特点优化了存储和查询的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化llm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "llm_model = \"Qwen2.5-14B\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"None\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://10.58.0.2:8000/v1\"\n",
    "# llm_completion = OpenAI(model_name=\"Qwen2.5-14B\")\n",
    "# llm_chat = OpenAIChat(model_name=\"Qwen2.5-14B\")\n",
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\d2lc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 初始化embedding方式\n",
    "# !pip install sentence_transformers\n",
    "# 每次都得翻墙很麻烦，直接离线到本地：\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"./all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化数据集下载 若需要搭建自己的向量数据库\n",
    "# import kagglehub\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"Cornell-University/arxiv\")\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 初始化向量数据库\n",
    "# 不使用本地内存向量数据库，而是提供的在线向量数据库\n",
    "# !pip install protobuf\n",
    "# !pip install pymilvus\n",
    "# 检索时，输入的数据也会先通过这个嵌入函数转换为向量，进而在数据库中查找相似向量\n",
    "\n",
    "# from langchain.vectorstores import Milvus\n",
    "# db = Milvus(embedding_function=embedding,collection_name='arXiv',connection_args={\"host\": \"10.58.0.2\", \"port\": \"19530\"})\n",
    "\n",
    "from pymilvus import connections\n",
    "connections.connect(\n",
    "  host='10.58.0.2',\n",
    "  port='19530'\n",
    ")\n",
    "\n",
    "from pymilvus import utility\n",
    "print(utility.has_collection(\"arXiv\"))\n",
    "from langchain.vectorstores import Milvus\n",
    "db = Milvus(embedding_function=embedding,collection_name='arxiv',connection_args={\"host\": \"10.58.0.2\", \"port\": \"19530\"})\n",
    "# 深坑，这里的arxiv的x不能大写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单测试\n",
    "\n",
    "简单查询向量数据库相关文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形成QA应用\n",
    "from langchain.chains import RetrievalQA\n",
    "retriever = db.as_retriever()\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Milvus' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m(\n\u001b[0;32m      2\u001b[0m   expr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeep learning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m   offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      4\u001b[0m   limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, \n\u001b[0;32m      5\u001b[0m   output_fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Milvus' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "from pymilvus import Collection\n",
    "collection = Collection(\"arxiv\")      # Get an existing collection.\n",
    "collection.load()\n",
    "\n",
    "res = db.query(\n",
    "  expr = \"deep learning\",\n",
    "  offset = 0,\n",
    "  limit = 10, \n",
    "  output_fields = [\"text\", \"comments\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The provided context does not discuss deep learning. It focuses on statistical learning, specifically the construction of predictors for a random variable $Y$ based on another random variable $X$, under conditions where the $Y$-part of the data is communicated at a finite bit rate. If you have questions about deep learning, I would be happy to say that I don't know and help find accurate information on that topic.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_stuff.run(\"deep learning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
